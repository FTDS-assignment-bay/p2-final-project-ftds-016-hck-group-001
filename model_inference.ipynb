{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductions \n",
    "\n",
    "This notebook is to show the model ability to predict the complaint and give desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:13:26.278086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nathanaelh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nathanaelh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nathanaelh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# for text preprocess\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# save model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_received          product    sub_product  \\\n",
      "0    2018-07-29  Debt collection        Medical   \n",
      "1    2020-03-20  Debt collection    Credit card   \n",
      "2    2022-04-19  Debt collection  I do not know   \n",
      "\n",
      "                                   issue                          sub_issue  \\\n",
      "0  Cont'd attempts collect debt not owed                      Debt was paid   \n",
      "1     False statements or representation  Attempted to collect wrong amount   \n",
      "2                  Communication tactics         Frequent or repeated calls   \n",
      "\n",
      "                        consumer_complaint_narrative  \\\n",
      "0  I do not own anymore debt from this bank anymo...   \n",
      "1  Why am I must pay double the amount of my bill...   \n",
      "2  STOP CALLING ME FOR NO REASON! I REALLY DESPIS...   \n",
      "\n",
      "                             company_public_response                 company  \\\n",
      "0  We're sorry to hear that. We will communicate ...         Genesis Lending   \n",
      "1  We're sorry to hear that. We will communicate ...                  Paypal   \n",
      "2  Hi, sorry to hear that. We will evaluate our p...  Roquemore Holdings LLC   \n",
      "\n",
      "  state zip_code            tags consumer_consent_provided? submitted_via  \\\n",
      "0    AE    092XX  Older American           Consent provided           Web   \n",
      "1    NJ    076XX  Older American           Consent provided           Web   \n",
      "2    NY    146XX  Older American           Consent provided           Web   \n",
      "\n",
      "  date_sent_to_company company_response_to_consumer timely_response?  \\\n",
      "0           2018-07-12                       Closed              Yes   \n",
      "1           2020-03-10                       Closed              Yes   \n",
      "2           2022-04-10                       Closed              Yes   \n",
      "\n",
      "  consumer_disputed?  complaint_id  \n",
      "0                 No       1807128  \n",
      "1                 No       2003104  \n",
      "2                 No       2204107  \n"
     ]
    }
   ],
   "source": [
    "# Assuming data_dummy is your dictionary\n",
    "data_dummy = {\n",
    "    'date_received': [\n",
    "        '2018-07-29', '2020-03-20', '2022-04-19'\n",
    "    ],\n",
    "    'product': [\n",
    "        'Debt collection', 'Debt collection', 'Debt collection'\n",
    "    ],\n",
    "    'sub_product': [\n",
    "        'Medical', 'Credit card', 'I do not know'\n",
    "    ],\n",
    "    'issue': [\n",
    "        \"Cont'd attempts collect debt not owed\", \"False statements or representation\", \"Communication tactics\"\n",
    "    ],\n",
    "    'sub_issue': [\n",
    "        \"Debt was paid\", \"Attempted to collect wrong amount\", \"Frequent or repeated calls\"\n",
    "    ],\n",
    "    'consumer_complaint_narrative': [\n",
    "        \"I do not own anymore debt from this bank anymore. Please dont send me any more debt bill. \", \"Why am I must pay double the amount of my bill. This is a harrasment and a scam in progress!\", \"STOP CALLING ME FOR NO REASON! I REALLY DESPISE THIS KIND OF MARKETING TACTICS!\"\n",
    "    ],\n",
    "    'company_public_response': [\n",
    "        \"We're sorry to hear that. We will communicate with billing division to solve this problem.\", \"We're sorry to hear that. We will communicate with billing division to check for this problem\", \"Hi, sorry to hear that. We will evaluate our program to suit best for our customer's need. Thank you\"\n",
    "    ],\n",
    "    'company': [\n",
    "        \"Genesis Lending\", \"Paypal\", \"Roquemore Holdings LLC\"\n",
    "    ],\n",
    "    'state': [\n",
    "        \"AE\", \"NJ\", \"NY\"\n",
    "    ],\n",
    "    'zip_code': [\n",
    "        \"092XX\", \"076XX\", \"146XX\"\n",
    "    ],\n",
    "    'tags': [\n",
    "        \"Older American\", \"Older American\", \"Older American\"\n",
    "    ],\n",
    "    'consumer_consent_provided?': [\n",
    "        \"Consent provided\", \"Consent provided\", \"Consent provided\"\n",
    "    ],\n",
    "    'submitted_via': [\n",
    "        \"Web\", \"Web\", \"Web\"\n",
    "    ],\n",
    "    'date_sent_to_company': [\n",
    "        \"2018-07-12\", \"2020-03-10\", \"2022-04-10\"\n",
    "    ],\n",
    "    'company_response_to_consumer': [\n",
    "        \"Closed\", \"Closed\", \"Closed\"\n",
    "    ],\n",
    "    'timely_response?': [\n",
    "        \"Yes\", \"Yes\", \"Yes\"\n",
    "    ],\n",
    "    'consumer_disputed?': [\n",
    "        \"No\", \"No\", \"No\"\n",
    "    ],\n",
    "    'complaint_id': [\n",
    "        1807128, 2003104, 2204107\n",
    "    ],\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_data_dummy = pd.DataFrame(data_dummy)\n",
    "\n",
    "# Display DataFrame\n",
    "print(df_data_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Combined Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine issue, sub_issue, and consumer_complaint_narrative into one column\n",
    "df_data_dummy['sentence'] = df_data_dummy['issue'] + ' ' + df_data_dummy['sub_issue'] + ' ' + df_data_dummy['consumer_complaint_narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define Stemming\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A Function for Text Preprocessing\n",
    "def text_preprocessing(text):\n",
    "  # Case folding\n",
    "  text = text.lower()\n",
    "\n",
    "  # Mention removal\n",
    "  text = re.sub(\"@[A-Za-z0-9_]+\", \" \", text)\n",
    "\n",
    "  # Hashtags removal\n",
    "  text = re.sub(\"#[A-Za-z0-9_]+\", \" \", text)\n",
    "\n",
    "  # Newline removal (\\n)\n",
    "  text = re.sub(r\"\\\\n\", \" \",text)\n",
    "\n",
    "  # Whitespace removal\n",
    "  text = text.strip()\n",
    "\n",
    "  # URL removal\n",
    "  text = re.sub(r\"http\\S+\", \" \", text)\n",
    "  text = re.sub(r\"www.\\S+\", \" \", text)\n",
    "\n",
    "  # Non-letter removal (such as emoticon, symbol (like μ, $, 兀), etc\n",
    "  text = re.sub(\"[^A-Za-z\\s']\", \" \", text)\n",
    "  text = re.sub(\"'\", \"\", text)\n",
    "\n",
    "  # Tokenization\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # Stopwords removal\n",
    "  tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "  # Stemming\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "  # Combining Tokens\n",
    "  text = \" \".join(tokens)\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    contd attempt collect debt owed debt paid anym...\n",
       "1    false statement representation attempted colle...\n",
       "2    communication tactic frequent repeated call st...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = df_data_dummy['sentence'].apply(lambda x: text_preprocessing(x))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "Prediction: [0. 1. 1.]\n",
      "label for predicted sentence\n",
      "- harsh complaint\n",
      "- mild complaint\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "predict_proba = model.predict(sentence)\n",
    "\n",
    "\n",
    "predict_proba[:,0] = tf.where(predict_proba[:,0] > 0.1, 1, 0)  # Thresholding light complaints at 0.1\n",
    "predict_proba[:,1] = tf.where(predict_proba[:,1] > 0.1, 1, 0)  # Thresholding harsh complaints at 0.1\n",
    "predict_proba[:,2] = tf.where(predict_proba[:,2] > 0.75, 1, 0)  # Thresholding mid complaints at 0.75\n",
    "\n",
    "label_1 = predict_proba[0]\n",
    "\n",
    "print(f'Prediction: {label_1}')\n",
    "predicted_label = []\n",
    "if label_1[0] == 1:\n",
    "    predicted_label.append('light complaint')\n",
    "if label_1[1] == 1:\n",
    "    predicted_label.append('harsh complaint')\n",
    "if label_1[2] == 1:\n",
    "    predicted_label.append('mild complaint')\n",
    "\n",
    "print('label for predicted sentence')\n",
    "for x in predicted_label:\n",
    "    print(f\"- {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires Immediate Attention\n"
     ]
    }
   ],
   "source": [
    "def response(prediction):\n",
    "    if (prediction == [0, 1, 1]).all() or \\\n",
    "       (prediction == [1, 0, 1]).all() or \\\n",
    "       (prediction == [0, 1, 0]).all() or \\\n",
    "       (prediction == [1, 1, 1]).all():\n",
    "        return 'Requires Immediate Attention'\n",
    "    else:\n",
    "        return 'Follow The Standard Time Protocol'\n",
    "\n",
    "# Generate the response\n",
    "response_message = response(label_1)\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this output the model have been successfully predict the complaint level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
